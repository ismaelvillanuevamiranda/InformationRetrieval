{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"ir.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Eh7GSdChuPcx","colab_type":"code","colab":{},"outputId":"ec9178f9-adee-4ca4-a3f5-5b8c095f6807"},"source":["# Speech and Language Processing\n","# Information Retrieval\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","import pandas as pd\n","from scipy.spatial.distance import cosine\n","\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","\n","def word2vec(word):\n","    #taken from https://stackoverflow.com/questions/29484529/cosine-similarity-between-two-words-in-a-list\n","    from collections import Counter\n","    from math import sqrt\n","\n","    # count the characters in word\n","    cw = Counter(word)\n","    # precomputes a set of the different characters\n","    sw = set(cw)\n","    # precomputes the \"length\" of the word vector\n","    lw = sqrt(sum(c*c for c in cw.values()))\n","\n","    # return a tuple\n","    return cw, sw, lw\n","\n","def cosdis(v1, v2):\n","    # which characters are common to the two words?\n","    common = v1[1].intersection(v2[1])\n","    # by definition of cosine distance we have\n","    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]\n","\n","\n","\n","def parseAlternatingLinesFile(file):     #-----------------------------\n","   # read a sequence of pairs of lines, e.g. text of webpage(s), name/URL\n","   sequenceA = []\n","   sequenceB = [] \n","   fp = open(file, 'r')\n","   expectingA = True \n","   for line in fp.readlines():\n","       if expectingA:\n","           sequenceA.append(line.rstrip())\n","           expectingA = False\n","       else:\n","           sequenceB.append(line.rstrip())\n","           expectingA = True\n","   fp.close()\n","   return sequenceA, sequenceB\n","\n","\n","def characterTrigrams(text):         #----------------------------\n","  return [text[i:i+3] for i in range(len(text)-3+1)]\n","\n","\n","def computeFeatures(text, trigramInventory):        #-----------------------------\n","    # catches the similarities between  \"social\" and \"societal\" etc. \n","    # but really should be replaced with something better\n","    finalTokens = {}\n","    \n","    \n","    #REMOVING PUNCTUATION\n","    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n","    textNo_punct = \"\"\n","    for char in text:\n","        if char not in punctuations:\n","            textNo_punct = textNo_punct + char        \n","        \n","    #UNIGRAMS and REMOVING STOP WORDS\n","    tokens = word_tokenize(textNo_punct)\n","    tokensNoStopWords = [w for w in tokens if not w in stop_words]    \n","    \n","    ps = PorterStemmer()    \n","    i=0\n","    for w in tokensNoStopWords:\n","        finalTokens[i] = ps.stem(w)\n","        i=i+1\n","    \n","    trigrams = tokensNoStopWords;\n","    counts = {}\n","    for trigram in trigrams:\n","        if trigram in trigramInventory:\n","            if trigram in counts:\n","                counts[trigram] += 1\n","            else:\n","                counts[trigram] = 1              \n","    return counts\n","   \n","\n","def computeSimilarity(dict1, dict2):   #-----------------------------\n","    matchCount = 0\n","    \n","    similarity=0\n","    for tri in dict1:\n","        for tri2 in dict2:\n","            vw1 = word2vec(tri)\n","            vw2 = word2vec(tri2)            \n","            similarity = similarity + cosdis(vw1,vw2)\n","    return similarity\n","\n","\n","def retrieve(queries, trigramInventory, archive):      #-----------------------------\n","    # returns an array: for each query, the top 3 results found\n","    top3sets = [] \n","    for query in queries:\n","        q = computeFeatures(query, trigramInventory)\n","        similarities = [] \n","        for d in archive:\n","            similarities.append(computeSimilarity(q, d))\n","        top3indices = np.argsort(similarities)[0:3]\n","        #print \"top three indices are \"\n","        #print top3indices\n","        top3sets.append(top3indices)  \n","    return top3sets\n","\n","def valueOfSuggestion(result, position, targets):   #-----------------------------\n","    weight = [1.0, .5, .25]\n","    if result in targets:\n","        return weight[max(position, targets.index(result))]\n","    else:\n","        return 0\n","\n","\n","def scoreResults(results, targets):   #-----------------------------\n","    merits = [valueOfSuggestion(results[i], i, targets) for i in [0,1,2]]\n","    return sum(merits)\n","\n","\n","def scoreAllResults(queries, results, targets, descriptor):   #-----------------------------\n","    print ('\\nScores for ' + descriptor)\n","    scores = [] \n","    for q, r, t in zip(queries, results, targets):\n","       print ('for query: ' + q)\n","       print (' results = ')\n","       print (r)\n","       print (' targets = ')\n","       print (t)\n","       s = scoreResults(r, t)\n","       print ('  score = %.3f' % s)\n","       scores.append(s)\n","    overallScore = np.mean(scores)\n","    print ('all scores')\n","    print (scores)\n","    print ('overall score is %.3f' % overallScore)\n","    return overallScore\n","\n","\n","def pruneUniqueNgrams(ngrams):        # ----------------------\n","    twoOrMore = {} \n","    print ('before pruning: %d ngrams across all documents' % len(ngrams))\n","    for key in ngrams:\n","        if ngrams[key] > 1:\n","            twoOrMore[key] = ngrams[key]\n","    print ('after pruning: %d ngrams across all documents' % len(twoOrMore))\n","    return twoOrMore\n","\n","def findAllNgrams(contents):          # ----------------------\n","    allTrigrams = {}\n","    finalTokens = {}\n","    merged = ''\n","    for text in contents:\n","        #print('++++++++++', text , '===============')\n","        \n","        #REMOVING PUNCTUATION\n","        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n","        textNo_punct = \"\"\n","        for char in text:\n","           if char not in punctuations:\n","               textNo_punct = textNo_punct + char                        \n","                \n","        #UNIGRAMS and REMOVING STOP WORDS\n","        tokens = word_tokenize(textNo_punct)\n","        tokensNoStopWords = [w for w in tokens if not w in stop_words]    \n","        \n","        ps = PorterStemmer()    \n","        i=0\n","        for w in tokensNoStopWords:\n","            finalTokens[i] = ps.stem(w)\n","            i=i+1\n","            #print(ps.stem(w))            \n","                \n","        for token in finalTokens:\n","            if token in allTrigrams:\n","                allTrigrams[token] += 1\n","            else:\n","                allTrigrams[token] = 1\n","    return allTrigrams\n","\n","\n","def targetNumbers(targets, nameInventory):        # ----------------------\n","    # targets is a list of strings, each a sequence of names\n","    targetIDs = []\n","    for target in targets:\n","      threeNumbers = [] \n","      for name in target.split():\n","          threeNumbers.append(nameInventory.index(name))\n","      targetIDs.append(threeNumbers)\n","    return targetIDs\n","          \n","\n","# main ----------------------------------------------------\n","import sys, numpy as np\n","\n","print('......... irStub .........')\n","contents, names =  parseAlternatingLinesFile('csFaculty.txt') \n","print ('read in pages for ')\n","print (names)\n","trigramInventory = pruneUniqueNgrams(findAllNgrams(contents))\n","archive = [computeFeatures(line, trigramInventory) for line in contents]\n","\n","#queryFile = 'testQueries.txt'\n","queryFile = 'trainingQueries.txt'\n","\n","queries, targets = parseAlternatingLinesFile(queryFile)\n","targetIDs = targetNumbers(targets, names)\n","results = retrieve(queries, trigramInventory, archive)\n","modelName = 'silly character trigram model'\n","scoreAllResults(queries, results, targetIDs, modelName + ' on ' + queryFile)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["......... irStub .........\n","read in pages for \n","['akbar', 'badreddin', 'ceberio', 'cheon', 'freudenthal', 'fuentes', 'gates', 'hossain', 'kiekintveld', 'kreinovich', 'longpre', 'novick', 'salamah', 'villanueva', 'ward', 'tosh', 'acosta']\n","before pruning: 3893 ngrams across all documents\n","after pruning: 3893 ngrams across all documents\n","\n","Scores for silly character trigram model on trainingQueries.txt\n","for query: Artificial Intelligence\n"," results = \n","[ 0 14 13]\n"," targets = \n","[5, 8, 11]\n","  score = 0.000\n","for query: AI\n"," results = \n","[ 0 14 13]\n"," targets = \n","[5, 8, 11]\n","  score = 0.000\n","for query: ML\n"," results = \n","[ 0 14 13]\n"," targets = \n","[5, 7, 14]\n","  score = 0.250\n","for query: Deep Learning\n"," results = \n","[ 0 14 13]\n"," targets = \n","[5, 7, 14]\n","  score = 0.250\n","for query: Neural Networks\n"," results = \n","[ 0 14 13]\n"," targets = \n","[5, 7, 14]\n","  score = 0.250\n","for query: Social Computing\n"," results = \n","[ 0 14 13]\n"," targets = \n","[13, 6, 0]\n","  score = 0.500\n","for query: Internet of Things\n"," results = \n","[ 0 14 13]\n"," targets = \n","[12, 16, 4]\n","  score = 0.000\n","for query: Mobile Netorks\n"," results = \n","[ 0 14 13]\n"," targets = \n","[4, 12, 15]\n","  score = 0.000\n","for query: Systems\n"," results = \n","[ 0 14 13]\n"," targets = \n","[4, 12, 15]\n","  score = 0.000\n","for query: research like Alan Black\n"," results = \n","[ 0 14 13]\n"," targets = \n","[14, 11, 5]\n","  score = 0.500\n","for query: Reliable Systems\n"," results = \n","[ 0 14 13]\n"," targets = \n","[4, 2, 12]\n","  score = 0.000\n","for query: reasoning under uncertainty\n"," results = \n","[ 0 14 13]\n"," targets = \n","[9, 2]\n","  score = 0.000\n","for query: logic and its applications\n"," results = \n","[ 0 14 13]\n"," targets = \n","[2, 9]\n","  score = 0.000\n","for query: theory\n"," results = \n","[ 0 14 13]\n"," targets = \n","[10, 9, 2]\n","  score = 0.000\n","for query: applications of AI\n"," results = \n","[ 0 14 13]\n"," targets = \n","[5, 7, 8]\n","  score = 0.000\n","for query: cybersecurity and\n"," results = \n","[ 0 14 13]\n"," targets = \n","[12, 10, 16]\n","  score = 0.000\n","for query: cyberdefense and security\n"," results = \n","[ 0 14 13]\n"," targets = \n","[16, 12, 10]\n","  score = 0.000\n","for query: software engineering\n"," results = \n","[ 0 14 13]\n"," targets = \n","[6, 12, 1]\n","  score = 0.000\n","for query: sustainable research software\n"," results = \n","[ 0 14 13]\n"," targets = \n","[1, 12]\n","  score = 0.000\n","for query: programming languages\n"," results = \n","[ 0 14 13]\n"," targets = \n","[3, 14]\n","  score = 0.500\n","for query: model-driven / model-based software dev\n"," results = \n","[ 0 14 13]\n"," targets = \n","[1, 3, 12]\n","  score = 0.000\n","for query: computer security\n"," results = \n","[ 0 14 13]\n"," targets = \n","[10, 16, 12]\n","  score = 0.000\n","for query: secure systems\n"," results = \n","[ 0 14 13]\n"," targets = \n","[16, 10, 12]\n","  score = 0.000\n","for query: intelligence applications\n"," results = \n","[ 0 14 13]\n"," targets = \n","[7, 14, 8]\n","  score = 0.500\n","for query: programming\n"," results = \n","[ 0 14 13]\n"," targets = \n","[3, 6, 12]\n","  score = 0.000\n","for query: programming langauge research\n"," results = \n","[ 0 14 13]\n"," targets = \n","[3]\n","  score = 0.000\n","for query: CS education\n"," results = \n","[ 0 14 13]\n"," targets = \n","[4, 0, 6]\n","  score = 0.500\n","for query: computer science education\n"," results = \n","[ 0 14 13]\n"," targets = \n","[4, 0, 6]\n","  score = 0.500\n","for query: smart cities\n"," results = \n","[ 0 14 13]\n"," targets = \n","[13, 6, 5]\n","  score = 0.250\n","for query: information systems\n"," results = \n","[ 0 14 13]\n"," targets = \n","[13, 0]\n","  score = 0.750\n","for query: advanced database management systems\n"," results = \n","[ 0 14 13]\n"," targets = \n","[13]\n","  score = 0.250\n","for query: V&V\n"," results = \n","[ 0 14 13]\n"," targets = \n","[12]\n","  score = 0.000\n","for query: KDD\n"," results = \n","[ 0 14 13]\n"," targets = \n","[7]\n","  score = 0.000\n","for query: urban issues\n"," results = \n","[ 0 14 13]\n"," targets = \n","[13]\n","  score = 0.250\n","all scores\n","[0, 0, 0.25, 0.25, 0.25, 0.5, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0.5, 0, 0, 0.5, 0.5, 0.25, 0.75, 0.25, 0, 0, 0.25]\n","overall score is 0.154\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.15441176470588236"]},"metadata":{"tags":[]},"execution_count":104}]},{"cell_type":"code","metadata":{"id":"miVk0pROuPc3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}